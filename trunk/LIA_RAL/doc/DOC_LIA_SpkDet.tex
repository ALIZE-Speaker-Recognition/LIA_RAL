\documentclass[a4paper]{article}
\usepackage{DOC_LIA_RAL}
\usepackage{amssymb}

\date{\today}
\title{\Large\bf LIA\_SpkDet Package Documentation}
\name{LIA Automatic Speaker Recognition Team}
\address{LIA/CERI Universit\'e d'Avignon, Agroparc,\\ BP 1228, 84911
Avignon Cedex 9, France\\
\{lia@lia.univ-avignon.fr\}}
\begin{document}
\href{http://www.lia.univ-avignon.fr}{\includegraphics[scale=0.8]{lia.eps}}\\
\ninept
\maketitle
\section{Introduction to LIA\_RAL}

This package aims at providing Automatic Speaker Detection related
programs based on the ALIZE toolkit. It contains two task-specific
sub-packages: LIA\_SpkDet related to Speaker Detection and LIA\_Seg
related to Speaker Diarization and acoustic segmentation. A library
containing useful methods is provided in LIA\_SpkTools as well as
useful, uncategorized programs in LIA\_Utils. This documentation is
dedicated to the Speaker Detection package, LIA\_SpkDet
\section{LIA\_SpkDet}
\label{sec:SpkDet}

\subsection{General Options}

Options described below are shared by most of the programs of LIA\_RAL.
The reader is invited to get deeper in the ALIZE way of working as the meaning of some options (marked with an $X$ in the ALIZE column) is closely related to the philosophy of ALIZE.


\subsubsection{Model related Options}
\begin{tabular}{|c|c||p{8cm}|p{0.8cm}|}
\hline Name & Example & Description & ALIZE\\
\hline
\hline distribType & GD & Specify the type of distribution & X\\
\hline mixtureDistribCount & 10 & Specify the number of gaussian distributions in the mixture & X\\
\hline loadMixtureFileFormat & RAW & Specify the loading / saving format of the distribution & X\\
\cline{1-2} saveMixtureFileFormat & XML & &\\
\hline loadMixtureFileExtension & .gmm & Specify the extension in order to save / to load a model & X\\
\cline{1-2}  saveMixtureFileExtension   & "" &  & X\\
\hline mixtureFilesPath & ./ & Specify the path where to load and save mixtures & X\\
\hline
\end{tabular}

\subsubsection{Feature related Options}
\begin{tabular}{|c|c||p{8cm}|p{0.8cm}|}
\hline Name & Example & Description & ALIZE\\
\hline
\hline loadFeatureFileExtension & .prm & Specify the extension in order to save / to load a feature file & X\\
\cline{1-2}  saveFeatureFileExtension & .norm.prm &  & X\\
\hline saveFeatureFileSPro3DataKind & FBCEPSTRA & Specify the saving SPro 3 format of the file & X\\
\hline loadFeatureFileFormat & SPRO3 & "" & X\\
\hline saveFeatureFileFormat & HTK & Specify the loading/saving format of a feature file & X\\
\hline featureFilesPath & ./ & Specify the path where to load and save feature files & X\\
\hline vectSize & 32 & Specify the dimension of vectors in the feature files & X\\
\hline featureServerMode & FEATURE\_WRITABLE & Specify the read/write mode of the featureServer (read-only by default) & X\\
\hline featureServerMemAlloc & 100000 & Specify the memory to allocate for the ALIZE buffer & X\\
\hline
\end{tabular}

\subsubsection{Segment, Labels, Clusters related Options}
\begin{tabular}{|c|c||p{8cm}|p{0.8cm}|}
\hline Name & Example & Description & ALIZE\\
\hline
\hline labelFilesPath & ./ & Specifiy the path where to load and save label files & X\\
\hline labelSelectedFrames & male & Specify the label to work with&\\
\hline useIdForSelectedFrame & & The label selected is the same as the name found in the input feature list&\\
\hline addDefaultLabel & true & When no label file is found, add a default label to all features&\\
\hline defaultLabel & male & Specify this default label&\\
\hline frameLength & 0.01 & When working in segmental mode, specify the ratio between the time unit found in the label files and the frame-based time unit&\\
\hline
\end{tabular}

\subsubsection{Misc. Option}
\begin{tabular}{|c|c||p{8cm}|p{0.8cm}|}
\hline Name & Example & Description & ALIZE\\
\hline
\hline minLLK & -200 & Specify minimum and maximum likelihood values & X\\
\cline{1-2} maxLLK & 200 &  & X\\
\hline bigEndian & false & Tune this option depending on your O.S. & X\\
\hline featureServerBufferSize  & ALL\_FEATURES & Algorithm Buffer & X\\
\hline Alize\_featureBuffer & 100 & Memory Buffer & X\\
\hline debug & true & Enable debug mode & \\
\hline verbose & true & Enable verbose mode & \\
\hline
\end{tabular}

\subsection{EnergyDetector}

\subsubsection{Features}
EnergyDetector aims at analyzing the energy component of input
features by producing an output label file labeling features with
highest energy. This is a typical speech/non-speech detection. The
output label files get their label from the
\textit{labelOutputFrames} option. The process of selecting files is
done via two parameters:
\begin{itemize}
\item \textit{mixtureDistribCount} is used as the frames are selecting by the analysis of a GMM learned on them (use 2 or 3)
\item \textit{alpha} is the percentage of frames selected in the central gaussian.
\end{itemize}

\subsubsection{Compulsory options}

\begin{tabular}{|c|c||p{8cm}|}
\hline Name & Example & Description\\
\hline
\hline inputFeatureFileName & test1 & Name of the features to work with, can be a list with a .lst extension\\
\hline labelOutputFrames &  speech & Label affected to selected frames\\
\hline saveLabelFileExtension & .enr.lbl & Label file to save extension\\
\hline nbTrainIt & 10 & Number of EM iterations to estimate energy distribution\\
\hline varianceFlooring & 0.5 & variance control parameters\\
\cline{1-2} varianceCeiling & 10 & \\
\hline alpha & 0.25 & Percentage of frames selected in the central gaussian, idle when mixtureDistribCount==2\\
\hline featureServerMask & 16 & In this case, energy detection is done on a single dimension of the input vectors\\
\hline baggedFrameProbabilityInit & 0.1 & Specify the ratio between selected frames and the total number of frames used for initialisation, in this case 1 out of ten frames are took in account\\
\hline
\end{tabular}

\subsection{NormFeat}
\subsubsection{Features}
NormFeat aims at processing input speech related features (MFCC,
LFCC, ...) by applying any kind of normalization. Its main
functionality is to map the distribution of input features on
another one, e.g. when one wants their features to fit a gaussian
distribution of 0 -mean and 1 -variance.

\subsubsection{Compulsory options}

\begin{tabular}{|c|c||p{8cm}|}
\hline Name & Example & Description\\
\hline
\hline mode & norm & Specify the mode of NormFeat: norm is for feature normalization on a $\aleph(0,1)$ distribution, info gives mean and std for each component, featMap computes the feature Mapping\\
\hline inputFeatureFileName & ./lst/foo.lst & Name of the features to work with, can be a list with a .lst extension\\
\hline segmentalMode & false & When working in segmental Mode, stats and normalization are computed for each segment independently\\
\hline writeAllFeatures & true & When set to true, all features on the original file are written, when set to false, only normalized features are written\\
\hline indepModel & CI & These two options are only compulsory in featMap mode. The first gives the channel independent model, being the target distribution to map the features to, the second gives the channel dependent model of the features one wants to map\\
\cline{1-2} depModel & CD & \\
\hline
\end{tabular}

\subsubsection{Example}
An input feature file is obtained from a signal with 2 different
speakers of two different genders. The objective is to make the
distribution of the features belonging to the male fit
$\aleph(0,1)$.
The corresponding label file might look like this:\\
0 120.00 male\\
120.00 154.00 female\\
154.00 200 male\\

Two steps are necessary to achieve this goal:
\begin{itemize}
\item The first step takes into account only the male features, given by the labelSelectedFrame==male  option, compute the mean and covariance on all segments belonging to this label (thanks to the  --segmentalMode option tuned to false), then make them fit the normal distribution. The remaining female features are written thanks to the writeAllFeatures=true option
\item The second step only consists of repeating the first step while changing the labelSelectedFrame option to female\\
Command Line: ./NormFeat.exe --config NormFeat.cfg
\end{itemize}

\subsubsection{Feature Mapping}
FeatureMapping is an extension of mapping the input feature
distribution to a distribution different from $\aleph(0,1)$. The aim
of this mode is to map the current input feature to the best
gaussian of a channel independent model. The knowledge of the
belonging of the current feature to a channel dependent model is
stored in a label file. Another program is necessary to create this
latter.
One will have to repeat the following command line as many as the number of existing channel dependent models.\\
Command Line: NormFeat.exe --config cfg/Normfeat.cfg --mode featMap --indepModel ./World --depModel <./Cellular ./Landline ./Court>

\subsection{TrainWorld}
\subsubsection{Features}
TrainWorld is a generic application of learning a Gaussian Mixture Model via the EM (Expectation - Maximization) algorithm.\\
Initialization is done by picking features randomly in the \textit{inputFeatureFilename} (this parameter can be a list of feature files) according to the probability given by \textit{baggedFrameProbabilityInit}.\\
Input feature dimension and target GMM model's one do not have to match thanks to \textit{featureServerMask}.\\
As well as other programs of this toolkit, TrainWorld can work in segmental mode. The \textit{frameLength} option has to be filled when the given label file provides segmental time unit in an other unit than frame.\\
Two kinds of EM iterations are made during the learning process. The first one, which amount is given by \textit{nbTrainIt} picks features randomly in the \textit{inputFeatureFilename} according to the probability given by \textit{baggedFrameProbability}.\\
The learning process finishes by iterations given by the \textit{nbTrainFinalIt} option, for which all frames are taken into account.\\

\subsubsection{Compulsory options}

\begin{tabular}{|c|c||p{8cm}|}
\hline Name & Example & Description\\
\hline
\hline baggedFrameProbabilityInit & 0.1 & Specify the ratio between selected frames and the total number of frames used for initialization\\
\hline baggedFrameProbability & 0.01 & Specify the ratio between selected frames and the total number of frames used for training\\
\hline normalizeModel & false & Apply a $\aleph(0,1)$ mapping at the end of the learning process\\
\hline inputFeatureFilename & seg\_app.lst & Name of the features to work with, can be a list with a .lst extension\\
\hline fileInit & false & Specify if a model is available to skip the initialization step\\
\cline{1-2} inputWorldFilename  & xxx & \\
\hline initVarianceCeiling & 10 &\\
\cline{1-2} initVarianceFlooring & 1 & Variance control parameters, linearly decreasing or increasing from init to final\\
\cline{1-2} finalVarianceFlooring & 0.5 &\\
\cline{1-2} finalVarianceCeiling & 5 & \\
\hline nbTrainIt & 2 & Number of EM iterations related to baggedFrameProbability\\
\hline nbTrainFinalIt & 1 & Number of final EM iterations with no baggedFrameProbability\\
\hline outputWorldFilename & wld & Name of the resulting file model\\
\hline
\end{tabular}

\subsection{TrainTarget}
\subsubsection{Features}
TrainTarget is a generic application to achieve the adaptation
process of a model on data. In the ASR field, it is commonly used to
train target speakers by adapting a world model via a Maximum A
Posteriori method. Several MAP methods have been implemented:
\begin{itemize}
\item MAPConst: the random variable to estimate is computed by a linear combination of its value in the world model and its value obtained by an EM algorithm on the data. The weights of this combination are provided by the option \textit{alpha} ($\alpha$ for the world model and $1-\alpha$ for the client model).
These methods adapt a background GMM model on a specific set of data
by duplicating the world model and changing its means. Indeed, no
variance neither weights adaptation are implemented.
\item MAPOccDep: the random variable to estimate is computed by a linear combination of its value in the world model and its value obtained by an EM algorithm on the data. This method takes into account the \textit{a posteriori} probability $n$ for each gaussian. The weights of this combination are provided by the option \textit{MAPRegFactor} $r$ ($\frac{n}{n+r}$ for the world model and $1-\frac{n}{n+r}$ for the client model).
\end{itemize}

\subsubsection{Compulsory options}

\begin{tabular}{|c|c||p{8cm}|}
\hline Name & Example & Description\\
\hline
\hline baggedFrameProbability & 0.01 & Specify the ratio between selected frames and the total number of frames used for adaptation\\
\hline nbTrainIt & 5 & Number of EM iterations related to baggedFrameProbability\\
\hline nbTrainFinalIt & 1 & Number of final EM iterations with no baggedFrameProbability\\
\hline normalizeModel & false & Apply a $\aleph(0,1)$ mapping at the end of the learning process\\
\hline targetIdList & ndx & The input list: model on the first column, input feature filenames on others\\
\hline inputWorldFilename & wld & The a priori model\\
\hline MAPAlgo & MAPOccDep & Specify the adaptation method to use: MAPOccDep or MAPConst\\
\hline MAPRegFactor & 10 & parameter used by the MAPOccDep adaptation technique\\
\hline alpha &  0.75 & parameter used by the MAPAlgo adaptation technique \\
\hline
\end{tabular}

\subsection{ComputeTest}
\subsubsection{Features}
ComputeTest  is a generic application aiming at giving a score for a
test segment given a model. Multiple test segments with multiple
models are supported by this program. ComputeTest implements the
\textit{winning component} scoring method. This can be achieved by
filling the \textit{computeLLKWithTopDistribs}option with COMPLETE
and  \textit{topDistribsCount} by the desired number of components
to use. Instead of giving a single score related to one file and one
model, ComputeTest can give a score for each segment given in the
input label file, this done by filling the option
\textit{segmentalMode} with segmentLLR.

\subsubsection{Compulsory options}

\begin{tabular}{|c|c||p{8cm}|}
\hline Name & Example & Description\\
\hline
\hline segmentalMode & segmentLLR & if segmentLLR, gives a score for each input segment in the label file\\
\hline topDistribsCount & 10 & Number of gaussians used to compute the score\\
\hline computeLLKWithTopDistribs & COMPLETE & See ALIZE documentation for this\\
\hline ndxFileName & ndx & input file: test segment on the first column, models to test with on the others\\
\hline worldModelName & wld & background model\\
\hline gender & M & Gender of the ndx file\\
\hline outputFile & test1.res & Resulting score file\\
\hline
\end{tabular}

\subsection{ComputeNorm}
\subsubsection{Features}
ComputeNorm aims at applying normalization technique on speaker
detection scores. The various techniques implemented are znorm,
tnorm, and ztnorm. It has to be noted that the impostor trials and
related impostor scores, necessary for these normalization
techniques, are not performed by this program (ComputeTest has to be used for this task).\\
During the normalization process, it is possible to use all the
impostor scores ($selectType noSelect$) or to select part of them,
either by retrieving the N best ones ($selectType
selectNBestByTestSegment$) (the N impostors for which the
likelihoods between their models and the test signal are the
greatest ones) or by reading impostor cohort from a given client
dependent list ($selectType selectTarget\-DependentCohortInFile$).
For the latter, the form of the client dependent list has to be one
impostor id per line (the impostor id being related to those used in
the Z/T/ZTnorm score files). Note: ComputeNorm program currently
works only on non segmental input file NIST.

\subsubsection{Compulsory options}
\begin{tabular}{|c|c||p{8cm}|}
\hline Name & Example & Description\\
\hline
\hline outputFile & test1.nist & nist normalized score file\\
\hline normType  & znorm tnorm ztnorm & Normalization technique to apply\\
\hline testNistFile & nist & input file: client score file in NIST format (V. 2003)\\
\hline tnormNistFile & nist & input file: tnorm score file in NIST format (V. 2003) read if normType=tnorm or ztnorm\\
\hline znormNistFile & nist & input file: znorm score file in NIST format (V. 2003) read if normType=znorm or ztnorm\\
\hline ztnormNistFile & nist & input file: ztnorm score file in NIST format (V. 2003) read if normType=ztnorm\\
\hline selectType & noSelect & specify how a set of impostor score may be selected (see description of the program)\\
 & selectNBestByTestSegment& \\
 & selectTargetDependentCohortInFile & \\
\hline cohortFilePath & path & path where client dependent cohort files may be read\\
\hline cohortFileExt & extension & extension to use with dependent cohort files (the name of the file being the id of the client\\
\hline znormCohortNb & integer & size (N) of znorm impostor cohort for the selectNBestByTestSegment selection technique\\
\hline tnormCohortNb & integer & size (N) of tnorm impostor cohort for the selectNBestByTestSegment selection technique\\
\hline maxSegNb & integer & Maximum number of segment tests to be authorized\\
\hline maxScoreDistribNb & integer & Maximum number of impostor scores to be authorized\\
\hline maxIdNb & integer & Maximum number of client id to be authorized\\
\hline maxSegNb & integer & Maximum number of Segment tests to be authorized\\
\hline outputFile & test1.res & Resulting score file\\
\hline
\end{tabular}

\end{document}
